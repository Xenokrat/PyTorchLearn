{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameters\n",
    "\n",
    "input_size = 28*28  # размер изображения в точках\n",
    "hidden_size = 500   # нейронов в скрытом слое\n",
    "num_classes = 10    # количество распознаваемых классов (10 цифр)\n",
    "n_epochs = 2        # количество эпох\n",
    "batch_szie = 4      # размер мини-пакета входных данных\n",
    "lr = 0.01           # скорость обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "mnist_trainset = dsets.MNIST(\n",
    "    root=\"./data\", train=True, \n",
    "    download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "mnist_testset = dsets.MNIST(\n",
    "    root=\"./data\", train=False, \n",
    "    download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "print(len(mnist_trainset))\n",
    "print(len(mnist_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_szie, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_szie, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(X, y):\n",
    "        model.train()\n",
    "        yhat = model(X)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_classes)\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = make_train_step(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Epoch is 1\n",
      "Model - OrderedDict([('0.weight', tensor([[-0.0025,  0.0019, -0.0332,  ...,  0.0125,  0.0298, -0.0070],\n",
      "        [-0.0109, -0.0088, -0.0207,  ...,  0.0104, -0.0215,  0.0050],\n",
      "        [-0.0197, -0.0139,  0.0305,  ..., -0.0160,  0.0337, -0.0138],\n",
      "        ...,\n",
      "        [ 0.0045, -0.0029, -0.0012,  ..., -0.0279, -0.0219,  0.0053],\n",
      "        [ 0.0344,  0.0143,  0.0326,  ..., -0.0041, -0.0012, -0.0134],\n",
      "        [-0.0188, -0.0158,  0.0045,  ...,  0.0189,  0.0206, -0.0016]],\n",
      "       device='cuda:0')), ('0.bias', tensor([-0.9246, -0.0833, -0.0428, -0.0398, -0.0805, -0.0537, -0.0648, -0.3794,\n",
      "        -0.0780, -0.0821, -0.0758, -0.4057, -0.4451, -0.0818, -0.0563, -0.1679,\n",
      "        -0.0429, -0.0325, -0.0349, -0.0937, -0.4345, -0.0640, -0.1285, -0.0896,\n",
      "        -0.0684, -0.1771, -0.1965, -0.0199, -0.4781, -0.9789, -0.0713, -0.6778,\n",
      "        -0.4547, -0.0905, -0.3511, -0.0441, -0.0668, -2.6390, -0.0244, -1.0985,\n",
      "        -1.0266, -0.0258, -0.3179, -0.6001, -0.0418, -0.1059, -0.0545, -0.7882,\n",
      "        -0.0815, -0.0905, -0.0842, -0.0500, -0.0494, -0.0334, -0.0646, -0.0795,\n",
      "        -0.0926, -0.0710, -0.0609, -0.8715, -0.5079, -0.0575, -0.0720, -0.0965,\n",
      "        -0.0732, -1.3826, -0.0973, -0.3156, -0.0053, -0.0323, -0.0902, -0.0414,\n",
      "        -0.1525, -0.0534, -0.0606, -0.3586, -1.2066, -0.0828, -0.0750, -0.0298,\n",
      "        -0.0721, -0.0851, -0.0729, -0.0825, -0.0711, -0.7626, -0.0743, -0.0603,\n",
      "        -0.0444, -0.8922, -0.0487, -0.0810, -0.0879, -0.0488, -0.0801, -0.1094,\n",
      "        -0.0502, -0.0419, -0.0331, -0.0643, -0.0542, -0.0446, -0.3435, -0.0430,\n",
      "        -0.0818, -0.0827, -0.0635, -0.0779, -0.0484, -0.7282, -0.0486, -0.0122,\n",
      "        -0.0628, -0.0835, -0.0778, -0.0587, -0.0420, -0.0310, -0.0798, -0.0261,\n",
      "        -0.0102, -0.1025, -0.0700, -0.5193, -0.0696, -0.6281, -0.0625, -0.0807,\n",
      "        -0.0502, -1.0397, -0.5560, -0.0972, -0.0518, -0.1217, -2.0023, -0.0846,\n",
      "        -0.0805, -0.0793, -0.0386, -0.0266, -2.3017, -0.0615, -0.1013, -0.6140,\n",
      "        -0.0729, -1.1743, -0.0818, -0.0496, -0.7291, -0.0465, -0.0624, -0.0448,\n",
      "        -0.0668, -0.0793, -1.5136, -0.0307, -0.1758, -0.1647, -0.1611, -0.0779,\n",
      "        -0.0870, -0.0472, -0.2381, -0.2666, -0.0739,  0.3566, -0.0369, -0.0530,\n",
      "        -0.0514, -0.3309, -0.5832, -0.0762, -0.0436, -0.0426, -0.0562, -0.0620,\n",
      "        -0.3643, -0.0270, -0.0303, -0.0420, -0.1160, -0.0689, -1.0203, -0.8019,\n",
      "        -0.1263, -0.0508, -0.0780, -0.2352, -0.3417, -0.0672, -0.9840, -0.0858,\n",
      "        -0.3873, -0.0426, -0.0603, -0.1589, -0.1431, -0.0344, -0.1084, -0.0778,\n",
      "        -0.6729, -0.0730, -0.0245, -0.0633, -0.3276, -0.0934, -0.0229, -0.0697,\n",
      "        -0.5691, -0.0307, -0.0731, -0.0271, -0.1660, -0.2915, -0.0881, -0.1117,\n",
      "        -0.0377, -0.4168, -0.0763, -0.0650, -0.0825, -0.0812, -0.0300, -0.1571,\n",
      "        -0.0798, -0.0623, -0.1983, -0.0470, -0.1037, -0.0489, -0.0615, -0.4002,\n",
      "        -0.0287, -0.0467, -1.8479, -0.0213, -0.0764, -0.0328, -0.0417, -0.0774,\n",
      "        -2.1776, -0.0571, -0.0810, -0.0625, -0.0680, -0.0460, -0.0532, -0.0260,\n",
      "        -0.0672, -2.8260, -0.0947, -0.3779, -0.1210, -0.0362, -0.0778, -0.0310,\n",
      "        -0.0587, -0.0627, -0.0859, -3.6347, -0.1188, -0.0446, -0.0076, -0.0956,\n",
      "        -0.0771, -0.0325, -0.0583, -0.0491, -0.1388, -0.0504, -0.6001, -1.3247,\n",
      "        -1.2452, -0.0192, -0.0340, -0.0396, -0.0533, -0.0565, -0.0840, -0.0783,\n",
      "        -0.0484, -0.2606, -0.0296, -0.0697, -0.0540, -0.0456, -0.0348, -0.0604,\n",
      "        -0.0666, -0.0721, -0.1107, -0.0649, -0.0750, -1.0035, -1.9196, -0.1824,\n",
      "        -0.0864, -0.0687, -0.0842, -0.2402, -0.0317, -0.0532, -0.0299, -0.1028,\n",
      "        -1.1874, -0.1656, -0.0727, -0.0683, -0.0456, -0.0757, -0.0308, -0.0662,\n",
      "        -0.3050, -0.0825, -0.3384, -0.2890, -0.0721, -0.1434,  0.1878, -0.4731,\n",
      "        -0.0811, -0.0308, -0.0485, -0.0755, -0.0695, -0.1771, -0.0341, -2.0941,\n",
      "        -1.9868, -0.1306, -0.0791, -0.0202, -0.0623, -0.0330, -0.0544, -0.0906,\n",
      "        -0.0656, -0.0808, -0.0732, -0.0229, -0.0481, -1.3744, -1.8995, -0.1107,\n",
      "        -0.0679, -0.0354, -0.0162, -0.0242, -0.0545, -0.0824, -0.0686, -0.6028,\n",
      "        -0.3576, -0.0614,  0.3354, -0.0385, -0.0485, -1.5084, -0.0789, -0.3365,\n",
      "        -0.0660, -0.0899, -0.0550, -2.1737, -0.0684, -0.0295, -0.0900, -0.0891,\n",
      "        -0.0304, -0.0733, -0.7293, -0.0371, -0.0708, -0.4472, -0.0639, -0.0637,\n",
      "        -0.0371, -1.8690, -0.0652, -0.0958, -0.0729, -0.0340, -0.0862, -0.1113,\n",
      "        -0.0801, -0.2065, -0.0856, -0.0815, -0.2832, -1.8637, -0.0904, -0.0719,\n",
      "        -0.0548, -0.0460, -0.0309, -0.3396, -0.0444, -0.0740, -2.0772, -0.0728,\n",
      "        -0.0850, -0.0531, -0.0944, -1.0757, -0.0368, -0.0736, -0.0930, -0.0821,\n",
      "        -0.0814, -0.0401, -0.0574, -0.0421, -0.0388, -0.0517, -0.0569, -0.3705,\n",
      "        -0.0709, -0.0466, -0.0637, -0.0257, -0.0720, -0.1988, -0.0734, -0.0840,\n",
      "        -0.1109, -0.0334, -0.0653, -0.0913, -0.0749, -0.1528, -0.0484, -0.0321,\n",
      "        -0.0969, -0.1591, -0.0674, -0.4398, -0.0247, -0.0955,  0.4078, -0.0833,\n",
      "        -0.0714, -0.0832, -0.4478, -0.8904, -0.0300, -0.0841, -0.0761, -0.9458,\n",
      "        -0.0933, -0.0624, -1.3592, -0.2007, -0.2863, -0.1542, -0.0767, -0.5183,\n",
      "        -0.0822, -0.0491, -0.0453, -0.0133, -0.1123, -0.0776, -0.0576, -0.0877,\n",
      "        -0.0627, -0.0272, -0.0873, -0.0359, -0.0297, -0.0612, -0.9965, -0.4554,\n",
      "        -0.0326, -0.1383, -0.3982, -0.8165, -0.0924, -0.0637, -0.0884, -0.0595,\n",
      "        -0.0894, -0.1148, -0.3394, -0.2033, -0.0292, -0.0275, -0.0671, -0.3538,\n",
      "        -0.2305, -0.0674, -0.2805, -0.0509, -0.0863, -2.2772, -0.0368, -0.0295,\n",
      "        -0.1084, -0.0580, -0.0870, -0.0756], device='cuda:0')), ('2.weight', tensor([[-0.6681, -0.0413, -0.0974,  ..., -0.0374, -0.0436, -0.0722],\n",
      "        [-0.4589,  0.0464, -0.0977,  ..., -0.1012, -0.0528, -0.0839],\n",
      "        [ 0.1499, -0.0914, -0.0298,  ...,  0.0112, -0.0350, -0.0455],\n",
      "        ...,\n",
      "        [-1.0333,  0.0122, -0.0794,  ..., -0.0343,  0.0724, -0.0276],\n",
      "        [ 0.0481, -0.0375, -0.0318,  ..., -0.0486, -0.0512, -0.0774],\n",
      "        [-0.0271,  0.0650, -0.0272,  ..., -0.1141, -0.0506, -0.0836]],\n",
      "       device='cuda:0')), ('2.bias', tensor([ 0.3339, -1.0714, -0.5530, -0.0164, -0.1949, -0.6407, -1.1349, -0.9928,\n",
      "         1.7133,  0.6640], device='cuda:0'))])\n",
      "Loss - 0.010116443037986755\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        loss = train_step(images, labels)\n",
    "\n",
    "    print(f\"Epoch is {epoch}\")\n",
    "\n",
    "print(f\"Model - {model.state_dict()}\")\n",
    "print(f\"Loss - {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 93.09\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Точность: {round(100 * correct / total, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./data/mnist_full.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"./data/mnist_full.pt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Epoch is 1\n",
      "Epoch is 2\n",
      "Epoch is 3\n",
      "Epoch is 4\n",
      "Epoch is 5\n",
      "Epoch is 6\n",
      "Epoch is 7\n",
      "Epoch is 8\n",
      "Epoch is 9\n",
      "Epoch is 10\n",
      "Epoch is 11\n",
      "Epoch is 12\n",
      "Epoch is 13\n",
      "Epoch is 14\n",
      "Epoch is 15\n",
      "Точность: 96.82\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 16\n",
    "batch_szie = 64\n",
    "hidden_size = 1500\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_szie, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_szie, shuffle=False)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_classes),\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        loss = train_step(images, labels)\n",
    "\n",
    "    print(f\"Epoch is {epoch}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Точность: {round(100 * correct / total, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 эпохи - 90%\n",
    "- 4 эпохи - 93.05% \n",
    "- 8 эпох  - 93.53%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size=1 - 89.16%\n",
    "- batch_size=2 - 92.06%\n",
    "- batch_size=4 - 92.57%\n",
    "- batch_size=8 - 93.51%\n",
    "- batch_size=16 - 94.16%\n",
    "- batch_size=32 - 95.95%\n",
    "- batch_size=64 - 96.38%\n",
    "- batch_size=max - 59.04%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hidden_size=100 - 92.18%\n",
    "- hidden_size=250 - 92.64%\n",
    "- hidden_size=500 - 93.18%\n",
    "- hidden_size=750 - 93.09%\n",
    "- hidden_size=1000 - 93.34%\n",
    "- hidden_size=1500 - 93.59%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ReLU x2 - Точность: 92.8\n",
    "- ReLU x3 - Точность: 91.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LeakyReLU - Точность: 93.65\n",
    "- Tanh - Точность: 89.31\n",
    "- ELU - Точность: 92.89\n",
    "- Sigmoid - Точность: 90.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_training_results():\n",
    "    images, labels = next(iter(train_loader))\n",
    "    plt.imshow(images[0].reshape(28,28), cmap=\"gray\")\n",
    "    images = images.reshape(-1, 28*28).to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(f\"Predicted class is {predicted[0]}\")\n",
    "\n",
    "show_training_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
